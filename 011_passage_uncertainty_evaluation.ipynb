{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "output-file: passage_uncertainty_evaluation\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from nbdev import show_doc, nbdev_export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IR evaluation metrics with uncertainty estimates\n",
    "\n",
    "> Compare different metrics and their uncertainty in the passage ranking dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working with search engine apps, be it a text search or a recommendation system, part of the job is doing experiments around components such as ranking functions and deciding which experiments deliver the best result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial builds a text search app with [Vespa](https://vespa.ai/), feeds a sample of the passage ranking dataset to the app, and evaluates two ranking functions across three different metrics. **In addition to return point estimates of the evaluation metrics, we compute confidence intervals as illustrated in the plot below**. Measuring uncertainty around the metric estimates gives us a better sense of how significant is the impact of our changes in the application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](resources/passage/passage_uncertainty.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code and the data used in this end-to-end tutorial are available and can be reproduced in a Jupyter Notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Vespa application package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Vespa application package to perform passage ranking experiments using the `create_basic_search_package`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from learntorank.passage import create_basic_search_package\n",
    "\n",
    "app_package = create_basic_search_package()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can inspect how the [Vespa search definition](https://docs.vespa.ai/en/schemas.html) file looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "schema PassageRanking {\n",
      "    document PassageRanking {\n",
      "        field doc_id type string {\n",
      "            indexing: attribute | summary\n",
      "        }\n",
      "        field text type string {\n",
      "            indexing: index | summary\n",
      "            index: enable-bm25\n",
      "        }\n",
      "    }\n",
      "    fieldset default {\n",
      "        fields: text\n",
      "    }\n",
      "    rank-profile bm25 {\n",
      "        first-phase {\n",
      "            expression: bm25(text)\n",
      "        }\n",
      "        summary-features {\n",
      "            bm25(text)\n",
      "        }\n",
      "    }\n",
      "    rank-profile native_rank {\n",
      "        first-phase {\n",
      "            expression: nativeRank(text)\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(app_package.schema.schema_to_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we are going to compare two ranking functions. One is based on [NativeRank](https://docs.vespa.ai/en/reference/nativerank.html), and the other is based on [BM25](https://docs.vespa.ai/en/reference/bm25.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deploy the application package in a Docker container for local development. Alternatively, it is possible to deploy the application package to [Vespa Cloud](https://pyvespa.readthedocs.io/en/latest/deploy-vespa-cloud.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for configuration server, 0/300 seconds...\n",
      "Waiting for configuration server, 5/300 seconds...\n",
      "Waiting for application status, 0/300 seconds...\n",
      "Waiting for application status, 5/300 seconds...\n",
      "Waiting for application status, 10/300 seconds...\n",
      "Waiting for application status, 15/300 seconds...\n",
      "Waiting for application status, 20/300 seconds...\n",
      "Waiting for application status, 25/300 seconds...\n",
      "Waiting for application status, 30/300 seconds...\n",
      "Waiting for application status, 35/300 seconds...\n",
      "Finished deployment.\n"
     ]
    }
   ],
   "source": [
    "from vespa.deployment import VespaDocker\n",
    "\n",
    "vespa_docker = VespaDocker()\n",
    "app = vespa_docker.deploy(application_package=app_package)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the deployment is finished, we can interact with the deployed application through the `app` variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get sample data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can load passage ranking sample data with `PassageData.load`. By default, it will download pre-generated sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from learntorank.passage import PassageData\n",
    "\n",
    "data = PassageData.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassageData(corpus, train_qrels, train_queries, dev_qrels, dev_queries)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 1000\n",
      "Number of train queries: 100\n",
      "Number of train relevance judgments: 100\n",
      "Number of dev queries: 100\n",
      "Number of dev relevance judgments: 100\n"
     ]
    }
   ],
   "source": [
    "data.summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed the application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the document corpus in a `DataFrame` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5954248</td>\n",
       "      <td>Why GameStop is excited for Dragon Age: Inquis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7290700</td>\n",
       "      <td>metaplasia definition: 1. abnormal change of o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5465518</td>\n",
       "      <td>Candice Net Worth. According to the report of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3100518</td>\n",
       "      <td>Under the Base Closure Act, March AFB was down...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3207764</td>\n",
       "      <td>There are a number of career opportunities for...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    doc_id                                               text\n",
       "0  5954248  Why GameStop is excited for Dragon Age: Inquis...\n",
       "1  7290700  metaplasia definition: 1. abnormal change of o...\n",
       "2  5465518  Candice Net Worth. According to the report of ...\n",
       "3  3100518  Under the Base Closure Act, March AFB was down...\n",
       "4  3207764  There are a number of career opportunities for..."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_df = data.get_corpus()\n",
    "corpus_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feed the data to the deployed application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful documents fed: 1000/1000.\n",
      "Batch progress: 1/1.\n"
     ]
    }
   ],
   "source": [
    "#|notest\n",
    "responses = app.feed_df(df=corpus_df, include_id=True, id_field=\"doc_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check the number of successfully fed documents through the responses status code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|notest\n",
    "sum([response.status_code == 200 for response in responses])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query the application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the dev set queries in a `DataFrame` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1101971</td>\n",
       "      <td>why say the sky is the limit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>712898</td>\n",
       "      <td>what is an cvc in radiology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>154469</td>\n",
       "      <td>dmv california how long does it take to get id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>930015</td>\n",
       "      <td>what's an epigraph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>860085</td>\n",
       "      <td>what is va tax</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  query_id                                           query\n",
       "0  1101971                    why say the sky is the limit\n",
       "1   712898                     what is an cvc in radiology\n",
       "2   154469  dmv california how long does it take to get id\n",
       "3   930015                              what's an epigraph\n",
       "4   860085                                  what is va tax"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_queries_df = data.get_queries(type=\"dev\")\n",
    "dev_queries_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the first query text to use as an example when querying our passage search application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'why say the sky is the limit'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_query = dev_queries_df.loc[0, \"query\"]\n",
    "sample_query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query with QueryModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the `bm25` [QueryModel](https://pyvespa.readthedocs.io/en/latest/reference-api.html#querymodel), which uses [Vespa's weakAnd](https://docs.vespa.ai/en/reference/query-language-reference.html#weakand) operator to match documents relevant to the query and use the `bm25` `rank-profile` that we defined in the application package above to rank the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from learntorank.query import QueryModel, WeakAnd, Ranking\n",
    "\n",
    "bm25_query_model = QueryModel(\n",
    "    name=\"bm25\", \n",
    "    match_phase=WeakAnd(hits=100), \n",
    "    ranking=Ranking(name=\"bm25\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once a `QueryModel` is specified, we can use it to query our application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'fields': {'doc_id': '7407715',\n",
      "             'documentid': 'id:PassageRanking:PassageRanking::7407715',\n",
      "             'sddocname': 'PassageRanking',\n",
      "             'summaryfeatures': {'bm25(text)': 11.979235042476953,\n",
      "                                 'vespa.summaryFeatures.cached': 0.0},\n",
      "             'text': 'The Sky is the Limit also known as TSITL is a global '\n",
      "                     'effort designed to influence, motivate and inspire '\n",
      "                     'people all over the world to achieve their goals and '\n",
      "                     'dreams in life. TSITL’s collaborative community on '\n",
      "                     'social media provides you with a vast archive of '\n",
      "                     'motivational pictures/quotes/videos.'},\n",
      "  'id': 'id:PassageRanking:PassageRanking::7407715',\n",
      "  'relevance': 11.979235042476953,\n",
      "  'source': 'PassageRanking_content'},\n",
      " {'fields': {'doc_id': '84721',\n",
      "             'documentid': 'id:PassageRanking:PassageRanking::84721',\n",
      "             'sddocname': 'PassageRanking',\n",
      "             'summaryfeatures': {'bm25(text)': 11.310323797415357,\n",
      "                                 'vespa.summaryFeatures.cached': 0.0},\n",
      "             'text': 'Sky Customer Service 0870 280 2564. Use the Sky contact '\n",
      "                     'number to get in contact with the Sky customer services '\n",
      "                     'team to speak to a representative about your Sky TV, Sky '\n",
      "                     'Internet or Sky telephone services. The Sky customer '\n",
      "                     'Services team is operational between 8:30am and 11:30pm '\n",
      "                     'seven days a week.'},\n",
      "  'id': 'id:PassageRanking:PassageRanking::84721',\n",
      "  'relevance': 11.310323797415357,\n",
      "  'source': 'PassageRanking_content'}]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "response = app.query(\n",
    "    query=sample_query, \n",
    "    query_model=bm25_query_model\n",
    ")\n",
    "pprint(response.hits[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query with Vespa Query Language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also translate the query created with the `QueryModel` into the [Vespa Query Language (YQL)](https://docs.vespa.ai/en/query-language.html) by setting `debug_request=True`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ranking': {'listFeatures': 'false', 'profile': 'bm25'},\n",
      " 'yql': 'select * from sources * where ({targetHits: 100}weakAnd(default '\n",
      "        'contains \"why\", default contains \"say\", default contains \"the\", '\n",
      "        'default contains \"sky\", default contains \"is\", default contains '\n",
      "        '\"the\", default contains \"limit\"));'}\n"
     ]
    }
   ],
   "source": [
    "response = app.query(\n",
    "    query = sample_query, \n",
    "    query_model=bm25_query_model, \n",
    "    debug_request=True\n",
    ")\n",
    "yql_body = response.request_body\n",
    "pprint(yql_body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use Vespa YQL directly via the `body` parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'fields': {'doc_id': '7407715',\n",
      "             'documentid': 'id:PassageRanking:PassageRanking::7407715',\n",
      "             'sddocname': 'PassageRanking',\n",
      "             'summaryfeatures': {'bm25(text)': 11.979235042476953,\n",
      "                                 'vespa.summaryFeatures.cached': 0.0},\n",
      "             'text': 'The Sky is the Limit also known as TSITL is a global '\n",
      "                     'effort designed to influence, motivate and inspire '\n",
      "                     'people all over the world to achieve their goals and '\n",
      "                     'dreams in life. TSITL’s collaborative community on '\n",
      "                     'social media provides you with a vast archive of '\n",
      "                     'motivational pictures/quotes/videos.'},\n",
      "  'id': 'id:PassageRanking:PassageRanking::7407715',\n",
      "  'relevance': 11.979235042476953,\n",
      "  'source': 'PassageRanking_content'},\n",
      " {'fields': {'doc_id': '84721',\n",
      "             'documentid': 'id:PassageRanking:PassageRanking::84721',\n",
      "             'sddocname': 'PassageRanking',\n",
      "             'summaryfeatures': {'bm25(text)': 11.310323797415357,\n",
      "                                 'vespa.summaryFeatures.cached': 0.0},\n",
      "             'text': 'Sky Customer Service 0870 280 2564. Use the Sky contact '\n",
      "                     'number to get in contact with the Sky customer services '\n",
      "                     'team to speak to a representative about your Sky TV, Sky '\n",
      "                     'Internet or Sky telephone services. The Sky customer '\n",
      "                     'Services team is operational between 8:30am and 11:30pm '\n",
      "                     'seven days a week.'},\n",
      "  'id': 'id:PassageRanking:PassageRanking::84721',\n",
      "  'relevance': 11.310323797415357,\n",
      "  'source': 'PassageRanking_content'}]\n"
     ]
    }
   ],
   "source": [
    "yql_response = app.query(body=yql_body)\n",
    "pprint(yql_response.hits[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate query models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we want to evaluate and compare the `bm25_query_model` defined above with the `native_query_model` defined below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "native_query_model = QueryModel(\n",
    "    name=\"native_rank\", \n",
    "    match_phase=WeakAnd(hits=100), \n",
    "    ranking=Ranking(name=\"native_rank\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We specify three metrics to evaluate the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from learntorank.evaluation import (\n",
    "    Recall, \n",
    "    ReciprocalRank, \n",
    "    NormalizedDiscountedCumulativeGain\n",
    ")\n",
    "\n",
    "metrics = [\n",
    "    Recall(at=10), \n",
    "    ReciprocalRank(at=3), \n",
    "    NormalizedDiscountedCumulativeGain(at=3)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Point estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is straightforward to obtain point estimates of the evaluation metrics for each query model being compared. In this case, we computed the mean and the standard deviation for each of the metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from learntorank.evaluation import evaluate\n",
    "\n",
    "evaluation = evaluate(\n",
    "    app=app,\n",
    "    labeled_data=data.get_labels(type=\"dev\"), \n",
    "    eval_metrics=metrics, \n",
    "    query_model=[native_query_model, bm25_query_model], \n",
    "    id_field=\"doc_id\",\n",
    "    aggregators=[\"mean\", \"std\"]\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>bm25</th>\n",
       "      <th>native_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">recall_10</th>\n",
       "      <th>mean</th>\n",
       "      <td>0.935833</td>\n",
       "      <td>0.845833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.215444</td>\n",
       "      <td>0.342749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">reciprocal_rank_3</th>\n",
       "      <th>mean</th>\n",
       "      <td>0.935000</td>\n",
       "      <td>0.755000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.231977</td>\n",
       "      <td>0.394587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">ndcg_3</th>\n",
       "      <th>mean</th>\n",
       "      <td>0.912839</td>\n",
       "      <td>0.749504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.242272</td>\n",
       "      <td>0.381792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "model                       bm25  native_rank\n",
       "recall_10         mean  0.935833     0.845833\n",
       "                  std   0.215444     0.342749\n",
       "reciprocal_rank_3 mean  0.935000     0.755000\n",
       "                  std   0.231977     0.394587\n",
       "ndcg_3            mean  0.912839     0.749504\n",
       "                  std   0.242272     0.381792"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the nature of the data distribution of the metrics described above, it is not trivial to compute a confidence interval from the mean and the standard deviation computed above. In the next section, we solve this by using bootstrap sampling on a per query metric evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uncertainty estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of returning aggregated point estimates, we can also compute the metrics per query by setting `per_query=True`. This gives us more granular information on the distribution function of the metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_per_query = evaluate(\n",
    "    app=app,\n",
    "    labeled_data=data.get_labels(type=\"dev\"), \n",
    "    eval_metrics=metrics, \n",
    "    query_model=[native_query_model, bm25_query_model], \n",
    "    id_field=\"doc_id\",\n",
    "    per_query=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>query_id</th>\n",
       "      <th>recall_10</th>\n",
       "      <th>reciprocal_rank_3</th>\n",
       "      <th>ndcg_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>native_rank</td>\n",
       "      <td>1101971</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>native_rank</td>\n",
       "      <td>712898</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>native_rank</td>\n",
       "      <td>154469</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>native_rank</td>\n",
       "      <td>930015</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>native_rank</td>\n",
       "      <td>860085</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         model query_id  recall_10  reciprocal_rank_3  ndcg_3\n",
       "0  native_rank  1101971        1.0                1.0     1.0\n",
       "1  native_rank   712898        0.0                0.0     0.0\n",
       "2  native_rank   154469        1.0                0.0     0.0\n",
       "3  native_rank   930015        1.0                1.0     1.0\n",
       "4  native_rank   860085        0.0                0.0     0.0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_per_query.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then created a function that uses the evaluation per query data and computes uncertainty estimates via bootstrap sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from learntorank.stats import compute_evaluation_estimates\n",
    "\n",
    "estimates = compute_evaluation_estimates(\n",
    "    df = evaluation_per_query\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>model</th>\n",
       "      <th>low</th>\n",
       "      <th>median</th>\n",
       "      <th>high</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ndcg_3</td>\n",
       "      <td>bm25</td>\n",
       "      <td>0.863837</td>\n",
       "      <td>0.914415</td>\n",
       "      <td>0.954587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ndcg_3</td>\n",
       "      <td>native_rank</td>\n",
       "      <td>0.678673</td>\n",
       "      <td>0.751851</td>\n",
       "      <td>0.826443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>recall_10</td>\n",
       "      <td>bm25</td>\n",
       "      <td>0.890833</td>\n",
       "      <td>0.936667</td>\n",
       "      <td>0.974188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>recall_10</td>\n",
       "      <td>native_rank</td>\n",
       "      <td>0.778312</td>\n",
       "      <td>0.847083</td>\n",
       "      <td>0.915000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>reciprocal_rank_3</td>\n",
       "      <td>bm25</td>\n",
       "      <td>0.885000</td>\n",
       "      <td>0.935000</td>\n",
       "      <td>0.975000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>reciprocal_rank_3</td>\n",
       "      <td>native_rank</td>\n",
       "      <td>0.681667</td>\n",
       "      <td>0.757500</td>\n",
       "      <td>0.835000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              metric        model       low    median      high\n",
       "0             ndcg_3         bm25  0.863837  0.914415  0.954587\n",
       "1             ndcg_3  native_rank  0.678673  0.751851  0.826443\n",
       "2          recall_10         bm25  0.890833  0.936667  0.974188\n",
       "3          recall_10  native_rank  0.778312  0.847083  0.915000\n",
       "4  reciprocal_rank_3         bm25  0.885000  0.935000  0.975000\n",
       "5  reciprocal_rank_3  native_rank  0.681667  0.757500  0.835000"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then create plots based on this data to make it easier to judge the magnitude of the differences between ranking functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from plotnine import *\n",
    "\n",
    "print((ggplot(estimates) + \n",
    " geom_point(aes(\"model\", \"median\")) + \n",
    " geom_errorbar(aes(x=\"model\", ymin=\"low\",ymax=\"high\")) + \n",
    " facet_wrap(\"metric\") + labs(y=\"Metric value\")\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vespa_docker.container.stop(timeout=600)\n",
    "vespa_docker.container.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learntorank",
   "language": "python",
   "name": "learntorank"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
